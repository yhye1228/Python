{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.155187Z",
     "start_time": "2025-11-09T07:53:52.865838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "12784de1d48248e9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.606279Z",
     "start_time": "2025-11-09T07:53:58.160234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_images = []\n",
    "labels = [0]*5 + [1]*5\n",
    "\n",
    "for i in range(10):\n",
    "    file = f\"./my_images/img{i+1:02d}.jpg\"\n",
    "    image = cv.imread(file)\n",
    "    image = cv.resize(image, (96, 96))\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    my_images.append(image)\n",
    "\n",
    "X = np.array(my_images, dtype='float32') / 255.0\n",
    "y = np.array(labels)\n"
   ],
   "id": "5ffc2f68d4dec9a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.617683Z",
     "start_time": "2025-11-09T07:53:58.610440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ],
   "id": "898e148e6298ebfb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.632952Z",
     "start_time": "2025-11-09T07:53:58.622473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(X_train)\n"
   ],
   "id": "df4c22ae4dd72c3b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.726895Z",
     "start_time": "2025-11-09T07:53:58.636407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(96,96,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ],
   "id": "cab3374eb2fe99ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhye1\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.749759Z",
     "start_time": "2025-11-09T07:53:58.728903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ],
   "id": "12cfdcd439db2943",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:53:58.760173Z",
     "start_time": "2025-11-09T07:53:58.753805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ],
   "id": "a28e651d2c90cb1b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:54:05.371231Z",
     "start_time": "2025-11-09T07:53:58.765724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=2),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ],
   "id": "b69f01d13bdbfd28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 109ms/step - accuracy: 0.7500 - loss: 0.6915 - val_accuracy: 0.0000e+00 - val_loss: 0.7037\n",
      "Epoch 2/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.5000 - loss: 0.6898 - val_accuracy: 0.5000 - val_loss: 0.7082\n",
      "Epoch 3/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.6250 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.7090\n",
      "Epoch 4/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5000 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.7156\n",
      "Epoch 5/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.6250 - loss: 0.6887 - val_accuracy: 0.5000 - val_loss: 0.7179\n",
      "Epoch 6/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.5000 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.7204\n",
      "Epoch 7/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5000 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.7374\n",
      "Epoch 8/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.5000 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.7442\n",
      "Epoch 9/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3750 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.7568\n",
      "Epoch 10/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3750 - loss: 0.6916 - val_accuracy: 0.5000 - val_loss: 0.7412\n",
      "Epoch 11/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.5000 - loss: 0.6911 - val_accuracy: 0.5000 - val_loss: 0.7113\n",
      "Epoch 12/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.1250 - loss: 0.6950 - val_accuracy: 0.5000 - val_loss: 0.6827\n",
      "Epoch 13/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - accuracy: 0.3750 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6662\n",
      "Epoch 14/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3750 - loss: 0.6936 - val_accuracy: 1.0000 - val_loss: 0.6585\n",
      "Epoch 15/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.6250 - loss: 0.6950 - val_accuracy: 1.0000 - val_loss: 0.6561\n",
      "Epoch 16/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3750 - loss: 0.6943 - val_accuracy: 1.0000 - val_loss: 0.6559\n",
      "Epoch 17/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.5000 - loss: 0.6865 - val_accuracy: 0.5000 - val_loss: 0.6532\n",
      "Epoch 18/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.5000 - loss: 0.6924 - val_accuracy: 0.5000 - val_loss: 0.6575\n",
      "Epoch 19/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6250 - loss: 0.6917 - val_accuracy: 0.5000 - val_loss: 0.6693\n",
      "Epoch 20/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3750 - loss: 0.7008 - val_accuracy: 0.5000 - val_loss: 0.6838\n",
      "Epoch 21/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5000 - loss: 0.6941 - val_accuracy: 0.5000 - val_loss: 0.6909\n",
      "Epoch 22/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.7500 - loss: 0.6968 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
      "Epoch 23/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3750 - loss: 0.7041 - val_accuracy: 0.5000 - val_loss: 0.6887\n",
      "Epoch 24/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3750 - loss: 0.6951 - val_accuracy: 0.5000 - val_loss: 0.6906\n",
      "Epoch 25/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.6250 - loss: 0.6812 - val_accuracy: 0.5000 - val_loss: 0.6974\n",
      "Epoch 26/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.3750 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.7002\n",
      "Epoch 27/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.5000 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6956\n",
      "Epoch 28/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.5000 - loss: 0.6890 - val_accuracy: 0.5000 - val_loss: 0.6984\n",
      "Epoch 29/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5000 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.7102\n",
      "Epoch 30/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.5000 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.7145\n",
      "Epoch 31/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.7500 - loss: 0.6810 - val_accuracy: 0.5000 - val_loss: 0.7193\n",
      "Epoch 32/200\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5000 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.7414\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:54:05.526174Z",
     "start_time": "2025-11-09T07:54:05.375248Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"MY_DETECTOR_SMALLCNN.keras\")\n",
   "id": "3b563abd97d9a309",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:54:06.296584Z",
     "start_time": "2025-11-09T07:54:05.546496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_images = []\n",
    "for i in range(10):\n",
    "    file = f\"./test_images/img{i+1:02d}.jpg\"\n",
    "    image = cv.imread(file)\n",
    "    image = cv.resize(image, (96, 96))\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    test_images.append(image)\n",
    "\n",
    "test_images_arr = np.array(test_images, dtype='float32') / 255.0\n"
   ],
   "id": "f51fbd0007941e88",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:54:06.601361Z",
     "start_time": "2025-11-09T07:54:06.296584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_model = keras.models.load_model(\"MY_DETECTOR_SMALLCNN.keras\")\n",
    "predictions = cnn_model.predict(test_images_arr)\n"
   ],
   "id": "9c8bf0d95135d73a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 84ms/step\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:54:06.609571Z",
     "start_time": "2025-11-09T07:54:06.601361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, p in enumerate(predictions):\n",
    "    if p > 0.5:\n",
    "        print(f\"img{i+1:02d}.jpg → ✅ 내 얼굴 ({p[0]:.3f})\")\n",
    "    else:\n",
    "        print(f\"img{i+1:02d}.jpg → ❌ 타인 ({p[0]:.3f})\")\n"
   ],
   "id": "5f8f1668f1d4e340",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img01.jpg → ❌ 타인 (0.483)\n",
      "img02.jpg → ✅ 내 얼굴 (0.531)\n",
      "img03.jpg → ❌ 타인 (0.478)\n",
      "img04.jpg → ✅ 내 얼굴 (0.506)\n",
      "img05.jpg → ✅ 내 얼굴 (0.502)\n",
      "img06.jpg → ✅ 내 얼굴 (0.512)\n",
      "img07.jpg → ✅ 내 얼굴 (0.518)\n",
      "img08.jpg → ✅ 내 얼굴 (0.524)\n",
      "img09.jpg → ✅ 내 얼굴 (0.509)\n",
      "img10.jpg → ❌ 타인 (0.498)\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
