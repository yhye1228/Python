{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-09T12:57:57.637954Z"
    }
   },
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "my_images = []\n",
    "labels = [0] * 5 + [1] * 10\n",
    "\n",
    "for i in range(15):\n",
    "    file = f\"./my_images/img{i + 1:02d}.jpg\"\n",
    "    image = cv.imread(file)\n",
    "    image = cv.resize(image, (96, 96))\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    my_images.append(image)\n",
    "\n",
    "X = np.array(my_images, dtype='float32') / 255.0\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "def mixup(x, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    index = np.random.permutation(len(x))\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "\n",
    "def cutmix(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    index = np.random.permutation(len(x))\n",
    "    h, w = x.shape[1], x.shape[2]\n",
    "    cx = np.random.randint(w)\n",
    "    cy = np.random.randint(h)\n",
    "    cut_w = int(w * np.sqrt(1 - lam))\n",
    "    cut_h = int(h * np.sqrt(1 - lam))\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "    x_cutmix = x.copy()\n",
    "    x_cutmix[:, y1:y2, x1:x2, :] = x[index, y1:y2, x1:x2, :]\n",
    "    lam_adjusted = 1 - ((x2 - x1) * (y2 - y1) / (w * h))\n",
    "    y_cutmix = lam_adjusted * y + (1 - lam_adjusted) * y[index]\n",
    "    return x_cutmix, y_cutmix\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.25,\n",
    "    height_shift_range=0.25,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # MixUp 적용\n",
    "    X_train_mix, y_train_mix = mixup(X_train, y_train)\n",
    "\n",
    "    # CutMix 적용\n",
    "    X_train_mix, y_train_mix = cutmix(X_train_mix, y_train_mix)\n",
    "\n",
    "    # CNN 모델 정의\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(96, 96, 3)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train_mix, y_train_mix, batch_size=2),\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "test_images = []\n",
    "for i in range(10):\n",
    "    file = f\"./test_images/img{i + 1:02d}.jpg\"\n",
    "    image = cv.imread(file)\n",
    "    image = cv.resize(image, (96, 96))\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    test_images.append(image)\n",
    "\n",
    "X_test = np.array(test_images, dtype='float32') / 255.0\n",
    "\n",
    "predictions = np.zeros((len(X_test), 1))\n",
    "for model in models:\n",
    "    predictions += model.predict(X_test)\n",
    "predictions /= len(models)\n",
    "\n",
    "for i, p in enumerate(predictions):\n",
    "    if p > 0.5:\n",
    "        print(f\"img{i + 1:02d}.jpg → ✅ 내 얼굴 ({p[0]:.3f})\")\n",
    "    else:\n",
    "        print(f\"img{i + 1:02d}.jpg → ❌ 타인 ({p[0]:.3f})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 1/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 83ms/step - accuracy: 0.0000e+00 - loss: 0.9870 - val_accuracy: 0.3333 - val_loss: 0.7470\n",
      "Epoch 2/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.6871 - val_accuracy: 0.3333 - val_loss: 0.8591\n",
      "Epoch 3/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 0.3333 - val_loss: 0.9750\n",
      "Epoch 4/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 0.3333 - val_loss: 1.0840\n",
      "Epoch 5/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.6686 - val_accuracy: 0.3333 - val_loss: 1.2312\n",
      "Epoch 6/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.9301 - val_accuracy: 0.3333 - val_loss: 1.4452\n",
      "Epoch 7/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0000e+00 - loss: 0.5825 - val_accuracy: 0.3333 - val_loss: 1.5770\n",
      "Epoch 8/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0833 - loss: 0.6045 - val_accuracy: 0.3333 - val_loss: 1.7213\n",
      "Epoch 9/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 1.0934 - val_accuracy: 0.3333 - val_loss: 2.0093\n",
      "Epoch 10/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0833 - loss: 1.9883 - val_accuracy: 0.3333 - val_loss: 2.9129\n",
      "Epoch 11/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.8413 - val_accuracy: 0.3333 - val_loss: 3.7044\n",
      "Epoch 12/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0833 - loss: 0.5907 - val_accuracy: 0.3333 - val_loss: 4.4326\n",
      "Epoch 13/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0833 - loss: 1.1162 - val_accuracy: 0.3333 - val_loss: 4.9962\n",
      "Epoch 14/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 2.3489 - val_accuracy: 0.3333 - val_loss: 5.4715\n",
      "Epoch 15/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0833 - loss: 1.1659 - val_accuracy: 0.3333 - val_loss: 5.9517\n",
      "Epoch 16/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6846 - val_accuracy: 0.3333 - val_loss: 7.0097\n",
      "Epoch 17/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0833 - loss: 0.7578 - val_accuracy: 0.3333 - val_loss: 7.6082\n",
      "Epoch 18/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0833 - loss: 1.0435 - val_accuracy: 0.3333 - val_loss: 7.8782\n",
      "Epoch 19/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.6770 - val_accuracy: 0.3333 - val_loss: 8.7682\n",
      "Epoch 20/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.0000e+00 - loss: 0.8421 - val_accuracy: 0.3333 - val_loss: 10.0270\n",
      "Epoch 21/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0833 - loss: 0.5968 - val_accuracy: 0.3333 - val_loss: 11.2649\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 1/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 79ms/step - accuracy: 0.0000e+00 - loss: 0.6931 - val_accuracy: 1.0000 - val_loss: 0.6452\n",
      "Epoch 2/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.0000e+00 - loss: 0.6931 - val_accuracy: 1.0000 - val_loss: 0.6407\n",
      "Epoch 3/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.6931 - val_accuracy: 1.0000 - val_loss: 0.6359\n",
      "Epoch 4/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6931 - val_accuracy: 1.0000 - val_loss: 0.6307\n",
      "Epoch 5/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6931 - val_accuracy: 1.0000 - val_loss: 0.6250\n",
      "Epoch 6/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6930 - val_accuracy: 1.0000 - val_loss: 0.6189\n",
      "Epoch 7/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6930 - val_accuracy: 1.0000 - val_loss: 0.6122\n",
      "Epoch 8/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6930 - val_accuracy: 1.0000 - val_loss: 0.6050\n",
      "Epoch 9/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6930 - val_accuracy: 1.0000 - val_loss: 0.5973\n",
      "Epoch 10/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6930 - val_accuracy: 1.0000 - val_loss: 0.5889\n",
      "Epoch 11/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6929 - val_accuracy: 1.0000 - val_loss: 0.5799\n",
      "Epoch 12/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6929 - val_accuracy: 1.0000 - val_loss: 0.5703\n",
      "Epoch 13/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6929 - val_accuracy: 1.0000 - val_loss: 0.5599\n",
      "Epoch 14/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6929 - val_accuracy: 1.0000 - val_loss: 0.5488\n",
      "Epoch 15/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6929 - val_accuracy: 1.0000 - val_loss: 0.5369\n",
      "Epoch 16/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6928 - val_accuracy: 1.0000 - val_loss: 0.5242\n",
      "Epoch 17/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.6928 - val_accuracy: 1.0000 - val_loss: 0.5108\n",
      "Epoch 18/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6928 - val_accuracy: 1.0000 - val_loss: 0.4965\n",
      "Epoch 19/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.6928 - val_accuracy: 1.0000 - val_loss: 0.4814\n",
      "Epoch 20/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.6928 - val_accuracy: 1.0000 - val_loss: 0.4655\n",
      "Epoch 21/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6927 - val_accuracy: 1.0000 - val_loss: 0.4488\n",
      "Epoch 22/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6927 - val_accuracy: 1.0000 - val_loss: 0.4314\n",
      "Epoch 23/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6927 - val_accuracy: 1.0000 - val_loss: 0.4132\n",
      "Epoch 24/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.6927 - val_accuracy: 1.0000 - val_loss: 0.3945\n",
      "Epoch 25/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.0000e+00 - loss: 0.6927 - val_accuracy: 1.0000 - val_loss: 0.3751\n",
      "Epoch 26/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.0000e+00 - loss: 0.6926 - val_accuracy: 1.0000 - val_loss: 0.3553\n",
      "Epoch 27/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6926 - val_accuracy: 1.0000 - val_loss: 0.3352\n",
      "Epoch 28/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6926 - val_accuracy: 1.0000 - val_loss: 0.3147\n",
      "Epoch 29/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6926 - val_accuracy: 1.0000 - val_loss: 0.2942\n",
      "Epoch 30/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6926 - val_accuracy: 1.0000 - val_loss: 0.2736\n",
      "Epoch 31/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.2531\n",
      "Epoch 32/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.2327\n",
      "Epoch 33/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.2127\n",
      "Epoch 34/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.1930\n",
      "Epoch 35/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.1739\n",
      "Epoch 36/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 0.1553\n",
      "Epoch 37/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 0.1373\n",
      "Epoch 38/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 0.1202\n",
      "Epoch 39/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 0.1039\n",
      "Epoch 40/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 0.0887\n",
      "Epoch 41/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6923 - val_accuracy: 1.0000 - val_loss: 0.0745\n",
      "Epoch 42/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6923 - val_accuracy: 1.0000 - val_loss: 0.0616\n",
      "Epoch 43/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6923 - val_accuracy: 1.0000 - val_loss: 0.0500\n",
      "Epoch 44/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6923 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 45/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6923 - val_accuracy: 1.0000 - val_loss: 0.0309\n",
      "Epoch 46/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
      "Epoch 47/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0174\n",
      "Epoch 48/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "Epoch 49/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
      "Epoch 50/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 51/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6922 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 52/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 53/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0000e+00 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 8.3258e-04\n",
      "Epoch 55/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 4.5588e-04\n",
      "Epoch 56/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6921 - val_accuracy: 1.0000 - val_loss: 2.3686e-04\n",
      "Epoch 57/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 1.1627e-04\n",
      "Epoch 58/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 5.3677e-05\n",
      "Epoch 59/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 2.3185e-05\n",
      "Epoch 60/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 9.3207e-06\n",
      "Epoch 61/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 3.4665e-06\n",
      "Epoch 62/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 1.1853e-06\n",
      "Epoch 63/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 3.6997e-07\n",
      "Epoch 64/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 1.0465e-07\n",
      "Epoch 65/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 2.6602e-08\n",
      "Epoch 66/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 6.0244e-09\n",
      "Epoch 67/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6919 - val_accuracy: 1.0000 - val_loss: 1.2040e-09\n",
      "Epoch 68/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6918 - val_accuracy: 1.0000 - val_loss: 2.1018e-10\n",
      "Epoch 69/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6918 - val_accuracy: 1.0000 - val_loss: 3.1694e-11\n",
      "Epoch 70/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6918 - val_accuracy: 1.0000 - val_loss: 4.0806e-12\n",
      "Epoch 71/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.6918 - val_accuracy: 1.0000 - val_loss: 4.4297e-13\n",
      "Epoch 72/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6918 - val_accuracy: 1.0000 - val_loss: 4.0004e-14\n",
      "Epoch 73/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 2.9632e-15\n",
      "Epoch 74/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 1.7734e-16\n",
      "Epoch 75/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 8.4401e-18\n",
      "Epoch 76/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 3.1425e-19\n",
      "Epoch 77/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 8.9935e-21\n",
      "Epoch 78/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6917 - val_accuracy: 1.0000 - val_loss: 1.9426e-22\n",
      "Epoch 79/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6916 - val_accuracy: 1.0000 - val_loss: 3.1067e-24\n",
      "Epoch 80/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.6916 - val_accuracy: 1.0000 - val_loss: 3.6070e-26\n",
      "Epoch 81/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.6916 - val_accuracy: 1.0000 - val_loss: 2.9779e-28\n",
      "Epoch 82/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.6916 - val_accuracy: 1.0000 - val_loss: 1.7108e-30\n",
      "Epoch 83/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.6916 - val_accuracy: 1.0000 - val_loss: 6.6915e-33\n",
      "Epoch 84/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 1.7423e-35\n",
      "Epoch 85/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 2.9498e-38\n",
      "Epoch 86/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 87/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 88/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 89/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6915 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 90/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 91/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 92/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 93/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 94/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 95/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0000e+00 - loss: 0.6914 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 96/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6913 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 97/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6913 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 98/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6913 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 99/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.6913 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 100/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6913 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 101/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 102/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 103/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 104/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 105/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 106/200\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.6912 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93c675b483a305df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
