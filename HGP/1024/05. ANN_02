import numpy as np
import matplotlib.pyplot as plt
from numpy import shape

X = np.array([0.0, 1.0, 2.0])
y = np.array([3.0, 3.5, 5.5])
W = 0 # 기울기
b = 0 # 절편
lrate = 0.01 # 학습률
epochs = 1000 # 반복 횟수
n = float(len(X)) # 입력 데이터의 개수
# 경사 하강법
for i in range(epochs):
    y_pred = W*X + b # 예측값
    dW = (2/n) * sum(X * (y_pred-y))
    db = (2/n) * sum(y_pred-y)
    W = W - lrate * dW # 기울기 수정
    b = b - lrate * db # 절편 수정
# 기울기와 절편을 출력한다.
print (W, b)
# 예측값을 만든다.
y_pred = W*X + b
# 입력 데이터를 그래프 상에 찍는다.
plt.scatter(X, y)
# 예측값은 선그래프로 그린다.
plt.plot([min(X), max(X)], [min(y_pred), max(y_pred)], color='red')
plt.show()

#모멘텀(momentum)
#Adam
#RMSprop

#195p(입력, 출력을 맞춰주기)
# XOR를 학습하는 MLP를 작성
# multi layer(2층)
# deep learning(3층 이상)
#197p
import tensorflow as tf
import keras
from keras import Input
import numpy as np
# 데이터 (XOR 문제)
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[0]])
#(1)sequential(엄청오래 걸림) 
#(2)함수형 API
#Model클래스를 상속받아서...
model = tf.keras.models.Sequential()

model.add(Input(shape=(2,)))#**중요
model.add(tf.keras.layers.Dense(units=2, activation='sigmoid'))
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))#**출력이 하나

model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(learning_rate=0.3))#SGD : 확률적 경사 하강법
#optimizer : 신경망의 가중치를 어떻게 업데이트할지 결정하는 알고리즘

model.fit(X, y, batch_size=1, epochs=10000)

print(model.predict(X))

#206p
# MNIST 필기체 숫자 인식 (MLP)
import matplotlib.pyplot as plt
import tensorflow as tf
(train_images, train_labels),(test_images, test_labels) = tf.keras.datasets.mnist.load_data()
print(train_images.shape)

print(train_labels.shape)

train_images[0]
plt.imshow(train_images[0], cmap="Greys")

model = tf.keras.models.Sequential([], name="MNIST")

model.add(tf.keras.layers.Input(shape=(28*28,)))
model.add(tf.keras.layers.Dense(units=512, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(units=256, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(units=10, activation=tf.nn.softmax))

#데이터 전처리
train_images = train_images.reshape(60000, 28*28)
train_images = train_images/255.0

test_images = test_images.reshape(10000, 28*28)
test_images = test_images/255.0#입력값을 작게 만들기

print(test_labels[1])

test_labels = tf.keras.utils.to_categorical(test_labels)

print(test_labels[1])

train_labels = tf.keras.utils.to_categorical(train_labels)

print(train_labels[1])

model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.categorical_crossentropy, metrics=["accuracy"])

model.summary()

model.fit(x=train_images, y=train_labels, epochs=10, batch_size=128)

(test_loss, test_accuracy) = model.evaluate(test_images, test_labels)

print(test_accuracy)

print(test_loss)

#학습결과 저장
model.save("MNIST_PARAM.keras")
